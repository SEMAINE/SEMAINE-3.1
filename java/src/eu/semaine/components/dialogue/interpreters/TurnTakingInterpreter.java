/**
 * Copyright (C) 2009 University of Twente. All rights reserved.
 * Use is subject to license terms -- see license.txt.
 */

package eu.semaine.components.dialogue.interpreters;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.Map;

import javax.jms.JMSException;

import eu.semaine.components.Component;
import eu.semaine.components.dialogue.datastructures.EmotionEvent;
import eu.semaine.components.dialogue.test.DMLogger;
import eu.semaine.datatypes.stateinfo.AgentStateInfo;
import eu.semaine.datatypes.stateinfo.DialogStateInfo;
import eu.semaine.datatypes.stateinfo.StateInfo;
import eu.semaine.jms.message.SEMAINEMessage;
import eu.semaine.jms.message.SEMAINEStateMessage;
import eu.semaine.jms.receiver.StateReceiver;
import eu.semaine.jms.sender.StateSender;
import eu.semaine.system.CharacterConfigInfo;

/**
 * The TurnTakingInterpreter looks at the behaviour of the user and has to decide when is
 * a good moment to start speaking. When this moment is decided the decision is send forward.
 * 
 * Input
 * UserStateReceiver('semaine.data.state.user')		--> user speaking state and detected emotions
 * AgentStateReceiver('semaine.data.state.agent')	--> current character
 * 
 * Output
 * AgentStateSender('semaine.data.state.agent')		--> take/release turn messages
 * 
 * @author MaatM
 *
 */

public class TurnTakingInterpreter extends Component
{
	/* The four characters */
	public final static int POPPY = 1;
	public final static int PRUDENCE = 2;
	public final static int SPIKE = 3;
	public final static int OBADIAH = 4;
	
	/* Possible turn states */
	private final static int WAITING = 0;
	private final static int SILENT = 1;
	private final static int SPEAKING = 2;
	
	private HashMap<String,Integer> charNumbers = new HashMap<String,Integer>();
	
	/* Take/release turn threshold */
	private static int POPPY_TT_THRESHOLD; // = 60;
	private static int PRUDENCE_TT_THRESHOLD; // = 80;
	private static int SPIKE_TT_THRESHOLD; // = 30;
	private static int OBADIAH_TT_THRESHOLD; // = 100;
	private int curr_TT_Threshold = 100;
	
	private static int EXPECTING_ANSWER_TIMEOUT = 8000;
	
	private String convState = "listening";

	/* Senders and Receivers */
	private StateReceiver userStateReceiver;
	private StateReceiver agentStateReceiver;
	private StateReceiver dialogStateReceiver;
	private StateReceiver contextReceiver;
	private StateSender agentStateSender;
	private StateSender dialogStateSender;

	/* Turn state of speaker */
	private int userSpeakingState = 0; // 	0 = unknown, 1 = silence, 2 = speaking
	private long userSpeakingStateTime = 0;
	private long latestUtteranceLength = 0;
	
	/* Turn state of Agent */
	private int agentSpeakingState = 1; //	1 = silence, 2 = speaking
	private long agentSpeakingStateTime = 0;
	private int agentSpeakingIntention = 0; //	1 = silence, 2 = speaking
	private long agentSpeakingIntentionTime = 0;
	
	/*  The current character*/
	private static final String USER = "user";
	private int character;
	
	/* List of detected emotion events (generated by the EmotionInterpreter) */
	private ArrayList<EmotionEvent> detectedEmotions = new ArrayList<EmotionEvent>();
	private int recentEmotionCounter = 0;
	private int index = 0;
	
	/* If a backchannel was given this silence */
	private boolean backchannel_given = false;
	
	/* Most recent detected words */
	private String currentDetectedKeywords = "";
	
	private long previousMetaTime;

	/**
	 * Constructor of TurnTakingInterpreter
	 * Initializes the senders and receivers, and sets the waitingtime for Act()
	 * @throws JMSException
	 */
	public TurnTakingInterpreter() throws JMSException
	{
		super("TurnTakingInterpreter");
		
		charNumbers.put("poppy", POPPY);
		charNumbers.put("prudence", PRUDENCE);
		charNumbers.put("spike", SPIKE);
		charNumbers.put("obadiah", OBADIAH);
		
		waitingTime = 50;
		previousMetaTime = meta.getTime();

		userStateReceiver = new StateReceiver( "semaine.data.state.user.behaviour", StateInfo.Type.UserState);
		receivers.add( userStateReceiver );
		agentStateReceiver = new StateReceiver( "semaine.data.state.agent", StateInfo.Type.AgentState);
		receivers.add( agentStateReceiver );
		dialogStateReceiver = new StateReceiver( "semaine.data.state.dialog", StateInfo.Type.DialogState);
		receivers.add( dialogStateReceiver );
		contextReceiver = new StateReceiver("semaine.data.state.context", StateInfo.Type.ContextState);
		receivers.add( contextReceiver );
		
		agentStateSender = new StateSender( "semaine.data.state.agent", StateInfo.Type.AgentState, getName() );
		senders.add( agentStateSender );
		dialogStateSender = new StateSender("semaine.data.state.dialog", StateInfo.Type.DialogState, getName());
		senders.add(dialogStateSender);
		
		POPPY_TT_THRESHOLD = Integer.parseInt(CharacterConfigInfo.getInfo("Poppy").getSetting("TurnTakingThreshold"));
		PRUDENCE_TT_THRESHOLD = Integer.parseInt(CharacterConfigInfo.getInfo("Prudence").getSetting("TurnTakingThreshold"));
		SPIKE_TT_THRESHOLD = Integer.parseInt(CharacterConfigInfo.getInfo("Spike").getSetting("TurnTakingThreshold"));
		OBADIAH_TT_THRESHOLD = Integer.parseInt(CharacterConfigInfo.getInfo("Obadiah").getSetting("TurnTakingThreshold"));
	}

	
	/**
	 * Reads the message, filters out the detected user speaking state and the detected emotions, 
	 * and tries to determine if the agent should start speaking.
	 */
	public void react( SEMAINEMessage m ) throws JMSException
	{
		if (m instanceof SEMAINEStateMessage) {
			SEMAINEStateMessage sm = (SEMAINEStateMessage) m;
			StateInfo stateInfo = sm.getState();
			StateInfo.Type stateInfoType = stateInfo.getType();
			switch (stateInfoType) {
			case UserState:
				/* Update current detected words */
				if( stateInfo.hasInfo("userUtterance") ) {
					currentDetectedKeywords = stateInfo.getInfo("userUtterance");
				}

				/* Updates user speaking state (speaking or silent) */
				setUserSpeakingState(stateInfo);
				
				/* Updates detected emotions (valence, arousal, interest) */
				addDetectedEmotions(stateInfo);
				
				processHeadMovements( stateInfo );
				
				/* called to determine the turn state of the agent */
				determineAgentTurn();
				break;

			case DialogState:
				/* Processes Dialog state updates */
				/* updates agent speaking state */
				setAgentSpeakingState(stateInfo);
				
				if( stateInfo.hasInfo("agentTurnState") ) {
					convState = stateInfo.getInfo("agentTurnState");
				}
				
				break;
				
			case AgentState:
				/* Processes Agent state changes */
				/* processes an agent backchannel */
				processBackchannel(stateInfo);
				break;
				
			case ContextState:
				setCharacter( stateInfo );
				break;
				
		    default:
		    	// We could complain here if we were certain we don't expect other state infos, as in:
		    	// throw new MessageFormatException("Unexpected state info type: "+stateInfo.getType().toString());
			}
		}
	}
	
	public void processHeadMovements( StateInfo stateInfo ) throws JMSException
	{
		if( stateInfo.hasInfo("headGesture") && stateInfo.hasInfo("headGestureStarted") && stateInfo.hasInfo("headGestureStopped") ) {
			DMLogger.getLogger().log(meta.getTime(), "UserAction:HeadMovement type=" + stateInfo.getInfo("headGesture") );
			if( stateInfo.getInfo("headGesture").equals("NOD") ) {
				userSpeakingState = SILENT;
				userSpeakingStateTime = meta.getTime();
			} else if( stateInfo.getInfo("headGesture").equals("SHAKE") ) {
				userSpeakingState = SILENT;
				userSpeakingStateTime = meta.getTime();
			}
		}
	}
	
	public void updateCharacter( StateInfo stateInfo ) throws JMSException
	{
		if( stateInfo.hasInfo("character") ) {
			character = charNumbers.get( stateInfo.getInfo("character") );
		}
	}
	
	/**
	 * Called every 50ms, reevaluates the current situation and tries to determine if the agent
	 * should start talking. 
	 */
	public void act() throws JMSException
	{
		determineAgentTurn();
		
		// Determine if timeout of ExpectingAnswer is reached.
		if( agentSpeakingState == WAITING && agentSpeakingStateTime + EXPECTING_ANSWER_TIMEOUT < meta.getTime() ) {
			Map<String,String> info = new HashMap<String,String>();
			info.put("agentTurnState","listening");

			DialogStateInfo dsi = new DialogStateInfo(info, null);
			dialogStateSender.sendStateInfo(dsi, meta.getTime());
		}
	}
	
	/**
	 * Reads the received Message and tries to filter out the detected user speaking state.
	 * @param m - the received message
	 */
	public void setAgentSpeakingState(StateInfo dialogInfo)
	{
		if( dialogInfo.hasInfo("agentTurnState") ) {
			if( dialogInfo.getInfo("agentTurnState").equals("speaking") ) {
				backchannel_given = false;
				agentSpeakingState = SPEAKING;
				agentSpeakingStateTime = meta.getTime();
				detectedEmotions.clear();
				recentEmotionCounter = 0;
			} else if( dialogInfo.getInfo("agentTurnState").equals("listening") ) {
				backchannel_given = false;
				agentSpeakingState = SILENT;
				agentSpeakingStateTime = meta.getTime();
				if( userSpeakingState == SILENT ) {
					userSpeakingState = WAITING;
					userSpeakingStateTime = meta.getTime();
				} else if( userSpeakingState == WAITING ) {
					userSpeakingStateTime = meta.getTime();
				}
			}  else if( dialogInfo.getInfo("agentTurnState").equals("expectingAnswer") ) {
				backchannel_given = false;
				agentSpeakingState = WAITING;
				agentSpeakingStateTime = meta.getTime();
				if( userSpeakingState == SILENT ) {
					userSpeakingState = WAITING;
					userSpeakingStateTime = meta.getTime();
				} else if( userSpeakingState == WAITING ) {
					userSpeakingStateTime = meta.getTime();
				}
			}
		}
	}

	/**
	 * Reads the received Message and tries to filter out the detected user speaking state.
	 * @param m - the received message
	 */
	public void setUserSpeakingState(StateInfo userInfo)
	{
		if( userInfo.hasInfo("speaking") ) {
			if( userInfo.getInfo("speaking").equals("true") ) {
				if( userSpeakingState != SPEAKING ) {
					DMLogger.getLogger().log(meta.getTime(), "UserAction:UserStartedSpeaking" );
					log.debug("Detected user speaking");
					backchannel_given = false;
					userSpeakingState = SPEAKING;
					userSpeakingStateTime = meta.getTime();
				}
			} else if( userInfo.getInfo("speaking").equals("false") ) {
				if( userSpeakingState != SILENT ) {
					DMLogger.getLogger().log(meta.getTime(), "UserAction:UserStoppedSpeaking words=" + currentDetectedKeywords );
					log.debug("Detected user silent");
					latestUtteranceLength = meta.getTime() - userSpeakingStateTime;
					userSpeakingState = SILENT;
					userSpeakingStateTime = meta.getTime();
				}
			}
		}
	}
	
	/**
	 * Reads the received Message and tries to filter out a change of character
	 * @param am - the received message
	 */
	public void setCharacter(StateInfo agentInfo)
	{
		Map<String,String> agentInfoMap = agentInfo.getInfos();
		
		String newChar = agentInfoMap.get( "character" );
		if( newChar != null ) {
			newChar = newChar.toLowerCase();
			if( newChar.equals("poppy") ) {
				character = POPPY;
				curr_TT_Threshold = POPPY_TT_THRESHOLD;
			} else if( newChar.equals("prudence") ) {
				character = PRUDENCE;
				curr_TT_Threshold = PRUDENCE_TT_THRESHOLD;
			} else if( newChar.equals("spike") ) {
				character = SPIKE;
				curr_TT_Threshold = SPIKE_TT_THRESHOLD;
			} else if( newChar.equals("obadiah") ) {
				character = OBADIAH;
				curr_TT_Threshold = OBADIAH_TT_THRESHOLD;
			} else {
			}
		} else {
		}
	}
	
	public void processBackchannel(StateInfo agentInfo)
	{
		// TODO: To Fix
		Map<String,String> agentInfoMap = agentInfo.getInfos();
		
		String intention = agentInfoMap.get( "turnTakingIntention" );
		if( intention != null && intention.equals("backchannel") ) {
			backchannel_given = true;
		}
	}
	
	/**
	 * Reads the received Message and tries to filter out the detected Emotion Events.
	 * @param m - the received message
	 */
	public void addDetectedEmotions(StateInfo userInfo)
	{
		if( userInfo.hasInfo("valence") ) {
			float valence = Float.parseFloat( userInfo.getInfo("valence") );
			EmotionEvent ee = new EmotionEvent( meta.getTime(), 0, EmotionEvent.VALENCE, valence );
			if( detectedEmotions.size() == 0 || meta.getTime() - detectedEmotions.get(detectedEmotions.size()-1).getTime() > 500 ) {
				recentEmotionCounter++;
			}
			detectedEmotions.add( ee );
		}
		if( userInfo.hasInfo("arousal") ) {
			float arousal = Float.parseFloat( userInfo.getInfo("arousal") );
			EmotionEvent ee = new EmotionEvent( meta.getTime(), 0, EmotionEvent.AROUSAL, arousal );
			if( detectedEmotions.size() == 0 || meta.getTime() - detectedEmotions.get(detectedEmotions.size()-1).getTime() > 500 ) {
				recentEmotionCounter++;
			}
			detectedEmotions.add( ee );
		}
		if( userInfo.hasInfo("interest") ) {
			float interest = Float.parseFloat( userInfo.getInfo("interest") );
			EmotionEvent ee = new EmotionEvent( meta.getTime(), 0, EmotionEvent.INTEREST, interest );
			if( detectedEmotions.size() == 0 || meta.getTime() - detectedEmotions.get(detectedEmotions.size()-1).getTime() > 500 ) {
				recentEmotionCounter++;
			}
			detectedEmotions.add( ee );
		}
	}
	
	/**
	 * Determines if the agent should start speaking or not. It bases this decision
	 * on the speaking_intention, a value for how much the agent wants the turn.
	 */
	public void determineAgentTurn() throws JMSException
	{
		int speakingIntention = getSpeakingIntentionValue();
		if( speakingIntention >= curr_TT_Threshold && agentSpeakingIntention != SPEAKING && (agentSpeakingState == SILENT || agentSpeakingState == WAITING) ) {
			agentSpeakingIntention = SPEAKING;
			agentSpeakingIntentionTime = meta.getTime();
			sendAgentTurnState();
		} else if( speakingIntention < curr_TT_Threshold && agentSpeakingIntention != SILENT ) {
			agentSpeakingIntention = SILENT;
			agentSpeakingIntentionTime = meta.getTime();
			sendAgentTurnState();
		}
	}
	
	/**
	 * Calculates the speaking intention value for the current moment.
	 * This is a value for how much the agent wants the turn.
	 * This is calculated based on detected emotion events, the user speaking state, 
	 * the duration of this state, and the agent speaking state plus its duration.
	 * The higher the value, the higher the intention to speak.
	 * 
	 * Currently, the speaking intention value is the sum of these values: 
	 * user_silence_time_value: 	a value between 0 and 100 which is higher when the user is silent for a longer time (max is reached after 0.8 seconds).
	 * emotion_value: 				a value based on the number of detected emotion events. More detected events lead to a higher value.
	 * agent_silence_time_value: 	a value that's higher when the agent is silent (user is speaking) for a longer period (max is reached after 30 seconds).
	 * agent_end_wait_value:		a value that starts at -100 when the agent finishes its utterance, and in the next 2 seconds slowly rises (linear) to 0;
	 * user_not_responding_value:	a value that rises from 0 to 100 when the user does not start talking after an agent-turn. It starts after 2 seconds, and then rises to 100 in 4 seconds unless the user starts speaking.
	 * @return
	 */
	public int getSpeakingIntentionValue()
	{
		if( meta.getTime() < previousMetaTime ) {
			/* System clock reset */
			userSpeakingStateTime = meta.getTime();
			agentSpeakingStateTime = meta.getTime();
		}
		previousMetaTime = meta.getTime();
		
		int speakingIntention = 0;
		
		/* The components of the speaking intention value */
		int user_silence_time_value = 0;
		int emotion_value = 0;
		int agent_silence_time_value = 0;
		int agent_end_wait_value = 0;
		int user_not_responding_value = 0;
		
		/* silence_time_value */
		if( userSpeakingState == SILENT ) {
			double time = ((double)meta.getTime() - (double)userSpeakingStateTime)/1000;
			if( backchannel_given ) {
				time = time - 1;
			}
			//double value = Math.max( Math.min( -(Math.sqrt(time))+1, 100 ), 0 );
			
			double value;
			if( time >= 0 ) {
				//System.out.println("time: "+time);
				double a = 100;
				double b1 = 10;
				double r;
				if( convState.equals("listening") ) {
					r = 2;
				} else {
					r = 0.7;
				}
				double b = (b1/r);
				value = a /(1+Math.exp(-b*(time-(r/2))));
				//value = Math.max( Math.min( Math.pow(time+0.3,2), 1 ), 0 );
			} else {
				value = 0;
			}
			user_silence_time_value = (int)(value);
			//user_silence_time_value = (int)(value * 100);
		}
		
		/* emotion_value */
		emotion_value = Math.min( recentEmotionCounter*10, 30 );
		
		/* time_turn_value */
		if( agentSpeakingState == SILENT || agentSpeakingState == WAITING ) {
			double time = ((double)meta.getTime() - (double)agentSpeakingStateTime)/1000;
			double value = Math.min( (4/3)*time, 30 );
			agent_silence_time_value = (int)(value);
		}
		
		/* agent_end_wait_value */
		long agentSpeakingTime = meta.getTime() - agentSpeakingStateTime;
		long userSpeakingTime = meta.getTime() - userSpeakingStateTime;
		if( (agentSpeakingState == SILENT || agentSpeakingState == WAITING) && agentSpeakingTime < 1000 ) {
			agent_end_wait_value = ((int)(0.05*agentSpeakingTime - 100));
		}
		
		/* user_not_responding_value */
		//System.out.println("Agent:" + agentSpeakingState + ", User:" + userSpeakingState + ", userSpeakingTime: " + userSpeakingTime + ", agentSpeakingTime: " + agentSpeakingTime );
		if( (agentSpeakingState == SILENT || agentSpeakingState == WAITING ) && userSpeakingState == WAITING && Math.abs(agentSpeakingTime - userSpeakingTime) < 30  ) {
			if( userSpeakingTime < 2000 ) {
				// Do nothing
			} else if( userSpeakingTime > 6000 ) {
				user_not_responding_value = 100;
			} else {
				user_not_responding_value = ((int)(0.025*(agentSpeakingTime-2000)));
			}
		}
		
		/* Calculating the speaking intention value */
		speakingIntention = user_silence_time_value + emotion_value + agent_silence_time_value + agent_end_wait_value + user_not_responding_value;
		//System.out.println( speakingIntention + "	= " + user_silence_time_value + "	+ " + emotion_value + "	+ " + agent_silence_time_value + "	+ " + agent_end_wait_value + "	+ " + user_not_responding_value + "			: currTime: " + meta.getTime() );
		DMLogger.getLogger().log(meta.getTime(), speakingIntention + "	= " + user_silence_time_value + "	+ " + emotion_value + "	+ " + agent_silence_time_value + "	+ " + agent_end_wait_value + "	+ " + user_not_responding_value);
		
		return speakingIntention;
	}
	
	public void sendAgentTurnState() throws JMSException
	{
		Map<String,String> agentStateInfo = new HashMap<String,String>();
		if( agentSpeakingIntention == SPEAKING ) {
			agentStateInfo.put("turnTakingIntention", "startSpeaking");
			DMLogger.getLogger().log(meta.getTime(), "TurnTakingIntention:StartSpeaking");
		} else if( agentSpeakingIntention == SILENT ) {
			agentStateInfo.put("turnTakingIntention", "stopSpeaking");
			DMLogger.getLogger().log(meta.getTime(), "TurnTakingIntention:StartSpeaking");
		} else {
			return;
		}
		
		AgentStateInfo asi = new AgentStateInfo( agentStateInfo );
		agentStateSender.sendStateInfo(asi, meta.getTime());	
	}
}
